---
title: "Algorytmy rozwi¹zuj¹ce problem QAP"
author: "Micha³‚ KuŸma i Micha³‚ Biernacki"
date: "5 grudnia 2016"
output:
  html_document:
    keep_md: yes
  pdf_document: default
---

```{r setup, include=FALSE}
library(knitr)
library(dplyr)
library(ggplot2)
opts_chunk$set(echo = FALSE, warning = FALSE, tidy = TRUE, message = FALSE)
```

```{r func_def}
## Summarizes data.
## Gives count, mean, standard deviation, standard error of the mean, and confidence interval (default 95%).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summariezed
##   groupvars: a vector containing names of columns that contain grouping variables
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {
  
  library(plyr)

    # New version of length which can handle NA's: if na.rm==T, don't count them
    length2 <- function (x, na.rm=FALSE) {
        if (na.rm) sum(!is.na(x))
        else       length(x)
    }

    # This does the summary. For each group's data frame, return a vector with
    # N, mean, and sd
    datac <- ddply(data, groupvars, .drop=.drop,
      .fun = function(xx, col) {
        c(N    = length2(xx[[col]], na.rm=na.rm),
          mean = mean   (xx[[col]], na.rm=na.rm),
          sd   = sd     (xx[[col]], na.rm=na.rm),
          min = min     (xx[[col]], na.rm=na.rm)
        )
      },
      measurevar
    )

    # Rename the "mean" column    
    datac <- rename(datac, c("mean" = measurevar))

    datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean

    # Confidence interval multiplier for standard error
    # Calculate t-statistic for confidence interval: 
    # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
    ciMult <- qt(conf.interval/2 + .5, datac$N-1)
    datac$ci <- datac$se * ciMult

    
    library(dplyr)
    return(datac)
}
```

```{r load_data}
data <- read.csv2("qap_algorithms.csv", col.names = c("name", "result", "opt_result", "perm", "opt_perm", "time", "inst_size", "inst_name", "init_perm", "rev_neigh", "steps_count"),
                  dec = ".")
data <- data %>%
  mutate(result_dist = (result - opt_result) / opt_result)
```

## Opis problemu

QAP (Quadratic assignment problem) reprezentuje nastêpuj¹ce zadanie:

*Dane s¹ zbiory n lokalizacji i n oœrodków. Ka¿da para lokacji znajduje siê w okreœlonej odleg³oœci od siebie, a dla ka¿dej pary oœrodków znany jest przep³yw. Celem jest takie przypisanie oœrodków do lokalizacji, aby zminimalizowaæ sumê iloczynów odleg³oœci i przep³ywów.*

Problem wykorzystywany jest czêsto do zamodelowania zadania rozmieszczenia fabryk (oœrodków) w zestawie znanych lokalizacji. Jako przep³ywy podane s¹ wówczas interakcje, w jakie fabryki wchodz¹ wzajemnie (transport surowców, etc.).

Poniewa¿ problem nale¿y do grupy NP-trudnych, nie jest znany algorytm, który pozwoli³by na znalezienie dok³adnego rozwi¹zania w czasie wielomianowym. W celu osi¹gniêcia zadowalaj¹cych wyników czasowych uzyskuj¹c dobre rozwi¹zanie, wykorzystuje siê algorytmy heurystyczne i metaheurystyki.

## Operator s¹siedztwa

W projekcie korzystano z operatora s¹siedztwa 2-OPT, który dla ka¿dej permutacji zwraca s¹siedztwo z³o¿one ze wszystkich permutacji uzyskanych przez zamianê dwóch pozycji miejscami.

Wykorzystanie tego operatora sprawia, ¿e wielkoœæ s¹siedztwa ka¿dej permutacji wynosi n<sup>2</sup> (gdzie n to d³ugoœæ permutacji).

## Krótki opis zaimplementowanych algorytmów

### Random Search

Algorytm przeszukiwania losowego (Random Search) jest najprostszym z wykorzystanych w projekcie. Przez okreœlony czas losuje on rozwi¹zania i na koniec zwraca najlepsze z nich. Parametr czasowy stanowi jedyne kryterium stopu algorytmu.

### Local Search

Algorytm przeszukiwania lokalnego (Local Search) wyszukuje lepsze rozwi¹zania w zbiorach s¹siedztwa a¿ do osi¹gniêcia optimum lokalnego. Nie daje jednak ¿adnej gwarancji odnalezienia optimum globalnego. Algorytm zosta³ zaimplementowany w dwóch wersjach ró¿ni¹cych siê sposobem wyboru s¹siada, do którego algorytm powinien przejœæ.

- *Greedy Local Search* wybiera pierwszego s¹siada, który jest lepszy od obecnie rozpatrywanego rozwi¹zania.
- *Steepest Local Search* przeszukuje ca³e s¹siedztwo wybieraj¹c najlepszego s¹siada i przechodzi do niego, jeœli jest lepszy od obecnego rozwi¹zania.

Przeprowadzono eksperyment zliczaj¹cy, ilu s¹siadów oceniaj¹ obie wersje algorytmu, oraz ile kroków robi¹. Wyniki przedstawiono na poni¿szych wykresach. W celu lepszej czytelnoœci wykresów, wybrano instancje o wielkoœci mniejszej, ni¿ $n = 30$.

```{r gs_compare}
# Neighbours count
data_results <- data %>%
  filter(name == "Greedy" | name == "Steepest", inst_size < 30) %>%
  summarySE(measurevar = "rev_neigh", groupvars = c("name", "inst_size"))

ggplot(data_results, aes(x = inst_size, y = rev_neigh)) +
  geom_errorbar(aes(ymin = rev_neigh-se, ymax = rev_neigh+se), width=.1) +
  geom_point() +
  facet_wrap(~ name, ncol = 2) +
  ggtitle("Liczba s¹siadów ocenionych przez algorytm w jednej iteracji") +
  xlab("Rozmiar instancji problemu") +
  ylab("Liczba ocenionych s¹siadów") +
  theme_bw()

# Time
data_results <- data %>%
  filter(name == "Greedy" | name == "Steepest", inst_size < 30) %>%
  summarySE(measurevar = "steps_count", groupvars = c("name", "inst_size"))

ggplot(data_results, aes(x = inst_size, y = steps_count)) +
  geom_errorbar(aes(ymin = steps_count-se, ymax = steps_count+se), width=.1) +
  geom_point() +
  facet_wrap(~ name, ncol = 2) +
  ggtitle("Liczba kroków wykonanych przez algorytm w jednej iteracji") +
  xlab("Rozmiar instancji problemu") +
  ylab("Liczba wykonanych kroków") +
  theme_bw()
```

Powy¿sze wykresy pokazuj¹, ¿e w pe³nej iteracji *Steepest* wykonuje znacznie mniej kroków od algorytmu *Greedy*, jednak poniewa¿ za ka¿dym razem sprawdza wszystkich mo¿liwych s¹siadów, liczba ocenionych przez niego rozwi¹zañ jest wiêksza dla wiêkszoœci instancji problemu. Algorytm *Greedy* wykazuje du¿¹ niestabilnoœæ zarówno w liczbie wykonanych kroków, jak i ocenionych s¹siadów (Dla wiêkszoœci instancji odchylenia s¹ wiêksze, ni¿ w *Steepest*).

### Heurystyka

Algorytm heurystyczny buduje rozwi¹zanie w oparciu o predefiniowane regu³y, które zgodnie z za³o¿eniem maj¹ prowadziæ do dobrego wyniku.Zaproponowana w projekcie heurystyka dzia³a na bardzo naiwnym za³o¿eniu, ¿e ka¿dy element w permutacji ma swoj¹ jedn¹, najbardziej optymaln¹ pozycjê (w tej permutacji), i zawsze przesuwaj¹c ten element bli¿ej tego miejsca zwiêkszamy wartoœæ funkcji celu (zmniejszamy koszta). W takim przypadku problem ten sprowadza siê do problemu sortowania. Heurystyka rozwi¹zuje to dalej stosuj¹c podejœcie analogiczne, jak algorytm sortowania b¹belkowego, dziêki czemu z³o¿onoœæ obliczeniowa wynosi O(n<sup>2</sup>), gdzie n to rozmiar permutacji.
Pocz¹tkowa permutacja jest tworzona w sposób losowy, dziêki czemu heurystyka mo¿e ka¿dorazowo dla jednej instancji problemu zwracaæ ró¿ne wyniki.

```
  solution = randomSolution()
  value = solution.getValue()
  
  for (i = 0; i < n; i++) {
    for (j = i + 1; j < n; j++) {
      changeValue = valueOfChangingItemsAtPositions(i, j)
      if (changeValue < 0) {
        changeElementsAtPositions(i, j)
        value += changeValue
      }
    }
  }
```

### Simulated Annealing

Algorytm symulowanego wy¿arzania (simulated annealing) przeszukuje przestrzeñ rozwi¹zañ poprzez przechodzenie do losowego s¹siada, który poprawia, a przynajmniej za mocno nie pogarsza wartoœci funkcji celu. To czy algorytm przejdzie do pogarszaj¹cego s¹siada zale¿y od parametru temperatury. Pocz¹tkowo ustawiana jest taka wartoœæ temperatury, by 95% losowych s¹siadów by³o akceptowanych, a nastêpnie, co okreœlon¹ iloœæ kroków ([wielkoœæ instancji]<sub>2</sub>) jest on zmniejszany (w naszym zastosowaniu, jest temperatura mno¿ona razy 0.95, bo taka wartoœæ dawa³a najlepsze rezultaty w stosunku do czasu przetwarzania).
Algorytm koñczy swoje dzia³anie, gdy nie znajdzie akceptowalnego s¹siada w okreœlonej liczbie prób ([wielkoœæ instancji]<sub>2</sub>), lub gdy temperatura osi¹gnie tak¹ wartoœæ, ¿e prawdopodobieñstwo akceptacji ruchów pogarszaj¹cych bêdzie wynosi³o 0%.

### Tabu Search

Algorytm przeszukiwania tabu (tabu search) w ka¿dym etapie wybiera listê kilku najlepszych mo¿liwych ruchów (o rozmiarze [wielkoœæ instancji]/10). Dalej z tej listy wybierane s¹ kolejno najlepsze ruchy w stosunku do aktualnego stanu, a¿ lista nie zostanie pusta. Ruch odrzucany jest na 2 sposoby:

- Gdy strata jest zbyt du¿a, w tym z czasem dzia³ania akceptowalna strata jest coraz mniejsza. Analogicznie jak temperatura w algorytmie symulowanego wy¿arzania.
- Gdy ruch znajduje siê na liœcie tabu, akceptowany jest tylko je¿eli polepsza wartoœæ funkcji celu.

Lista tabu ma na celu zablokowanie "cofania" siê - s¹ na niej ruchy przeciwne (takie które przywróci³yby stan) do ruchów ostatnio wykonanych. W naszej implementacji ma ona rozmiar nie wiêkszy ni¿ [wielkoœæ instancji]/4. Po wykonaniu ka¿dego ruchu, ruch do niego przeciwny jest dodawany do listy, a najstarszy na liœcie jest odrzucany.
Algorytm koñczy swoje dzia³anie w podobny sposób jak algorytm symulowanego wy¿arzania - gdy przez du¿¹ liczbê operacji ([wielkoœæ instancji]<sub>2</sub>) nie zostanie wykonany ¿aden ruch, lub gdy prawdopodobieñstwo akceptacji ruchów pogarszaj¹cych bêdzie wynosi³o 0%.


## Porównanie odleg³oœci od optimum rozwi¹zañ uzyskanych przez badane algorytmy

Do okreœlenia odleg³oœci od optimum globalnego wykorzystano miarê opisan¹ wzorem:

$dist = \frac{Opt_{L} - Opt_{G}}{Opt_{G}}$

Dla ka¿dej badanej instancji wykonano 10 pomiarów. Porównano wyniki œrednie oraz najlepsze. Wyniki pomiarów zosta³y przedstawione na poni¿szych wykresach.

```{r results_compare}
data_results <- data %>%
  filter(inst_size < 100) %>%
  summarySE(measurevar = "result_dist", groupvars = c("name", "inst_size"))

ggplot(data_results %>% filter(name != "Random"), aes(x = inst_size, y = result_dist)) +
  geom_errorbar(aes(ymin = result_dist-se, ymax = result_dist+se), width=.1) +
  geom_point() +
  facet_wrap(~ name, ncol = 2) +
  ggtitle("Œrednia odleg³oœæ uzyskanego przez algorytm rozwi¹zania od optimum") +
  xlab("Rozmiar instancji problemu") +
  ylab("Odleg³oœæ od optimum") +
  theme_bw()

ggplot(data_results %>% filter(name == "Random"), aes(x = inst_size, y = result_dist)) +
  geom_errorbar(aes(ymin = result_dist-se, ymax = result_dist+se), width=.1) +
  geom_point() +
  ggtitle("Œrednia odleg³oœæ uzyskanego przez algorytm losowy rozwi¹zania od optimum") +
  xlab("Rozmiar instancji problemu") +
  ylab("Odleg³oœæ od optimum") +
  theme_bw()
```

```{r best_results_compare}
ggplot(data_results %>% filter(name != "Random"), aes(x = inst_size, y = min)) +
  geom_point() +
  facet_wrap(~ name, ncol = 2) +
  ggtitle("Minimalna odleg³oœæ uzyskanego przez algorytm rozwi¹zania od optimum") +
  xlab("Rozmiar instancji problemu") +
  ylab("Odleg³oœæ od optimum") +
  theme_bw()

ggplot(data_results %>% filter(name == "Random"), aes(x = inst_size, y = min)) +
  geom_point() +
  ggtitle("Minimalna odleg³oœæ od optimum - algorytm losowy") +
  xlab("Rozmiar instancji problemu") +
  ylab("Odleg³oœæ od optimum") +
  theme_bw()
```

Ze wzglêdu na diametralnie gorsze wyniki, dla lepszej czytelnoœci, wykres algorytmu *Random Search* przedstawiono na odrêbnej skali.

Zaobserwowaæ mo¿na wysok¹ niestabilnoœæ uzyskanych wyników dla niektórych instancji problemu (du¿e odchylenia standardowe dla ka¿dego algorytmu). Mo¿e to byæ spowodowane skomplikowan¹ przestrzeni¹ rozwi¹zañ. 

Wszystkie badane algorytmy zdaj¹ siê wykazywaæ niezale¿noœæ jakoœci rozwi¹zania koñcowego (odleg³oœci od optimum) od wielkoœci instancji. Ró¿nice w jakoœci koñcowego rozwi¹zania powodowane s¹ raczej ró¿nym stopniem skomplikowania powierzchni rozwi¹zañ dla danych instancji.

Algorytmy *Greedy* i *Steepest* osi¹gaj¹ bardzo podobne œrednie rozwi¹zania. Zaproponowana heurystyka zwraca nieznacznie gorsze rozwi¹zania od algorytmów przeszukiwania lokalnego, natomiast *Random* osi¹ga rozwi¹zania daleko gorsze od pozosta³ych (poza prostymi instancjami).

Algorytmy Simulated Annealing (SA) i Tabu Search (TS) wykazuj¹ wiêksz¹ niezale¿noœæ od stopnia skomplikowania instancji (mniejsze odchylenia od wyliczonej funkcji liniowej), szczególnie uwzglêdniaj¹c rozwi¹zanie najlepsze ze znalezionych

## Porównanie czasów wykonywania algorytmów

Poniewa¿ warunkiem stopu algorytmu *Random* jest up³yniêcie okreœlonego czasu (œredniego czasu wykonywania *Local Search*), jego wykresy zosta³y pominiête.

```{r times_compare}
data_times <- data %>%
  filter(name != "Random", inst_size < 100) %>%
  summarySE(measurevar = "time", groupvars = c("name", "inst_size"))

ggplot(data_times, aes(x = inst_size, y = time)) +
  geom_errorbar(aes(ymin = time-se, ymax = time+se), width=.1) +
  geom_point() +
  facet_wrap(~ name, ncol = 2) +
  ggtitle("Œredni czas dzia³ania algorytmu w milisekundach") +
  xlab("Rozmiar instancji problemu") +
  ylab("Czas dzia³ania algorytmu") +
  theme_bw()
```

```{r best_times_compare}
ggplot(data_times, aes(x = inst_size, y = min)) +
  geom_point() +
  facet_wrap(~ name, ncol = 2) +
  ggtitle("Najkrótszy czas dzia³ania algorytmu w milisekundach") +
  xlab("Rozmiar instancji problemu") +
  ylab("Czas dzia³ania algorytmu") +
  theme_bw()
```

Przedstawione powy¿ej wykresy czasu trwania iteracji algorytmów pokazuj¹ wielomianowy wzrost czasu trwania algorytmu wraz ze wzrostem wielkoœci instancji (czego mo¿na siê by³o spodziewaæ). Dla algorytmów *SA* i *TS* czas roœnie znacznie szybciej od pozosta³ych (wielomian wy¿szego stopnia).

Wykresy œredniego czasu dzia³ania pokazuj¹ rosn¹c¹ niestabilnoœæ mierzonego czasu (która nie jest jednak zale¿na jedynie od wielkoœci instancji). Najmniejsze odchylenia zanotowano dla algorytmu *Steepest LS*, co by³o do przewidzenia. W ka¿dym kroku oceni on tak¹ sam¹ liczbê s¹siadów (co zajmie tyle samo czasu), wiêc czas trwania algorytmu zale¿y wy³¹cznie od liczby wykonanych kroków. Poniewa¿ dla danej instancji wykonuje on zawsze mniej wiêcej tyle samo kroków (potwierdzaj¹ to niewielkie odchylenia standardowe na wykresie rozmiar instancji / liczba kroków), liczba odwiedzonych s¹siadów, a wiêc i czas trwania algorytmu cechuj¹ siê wysok¹ stabilnoœci¹.

Trudno jednoznacznie okreœliæ, który z algorytmów przeszukiwania lokalnego dzia³a szybciej. Dla niektórych instancji krótszy czas osi¹gn¹³ *Steepest*, dla innych *Greedy*. Jest to silnie zwi¹zane z kszta³tem przestrzeni rozwi¹zañ, a nie bezpoœrednio z wielkoœci¹ instancji.

## Efektywnoœæ algorytmów

Przeprowadzono analizê efektywnoœci algorytmów. Miarê efektywnoœci opracowano wed³ug za³o¿enia, ¿e najwy¿sz¹ efektywnoœæ ma algorytm, który zwraca rozwi¹zanie optymalne w czasie zerowym. Miarê efektywnoœci ograniczono do przedzia³u $[0, 1]$ wed³ug poni¿szego wzoru:

$efectiveness = \frac{1}{(dist + 1) * (time / 60000 + 1)}$

```{r efectiveness_compare}
data_ef <- data %>%
  mutate(ef = 1/ ((result_dist + 1) * (time/60000 + 1))) %>%
  summarySE(measurevar = "ef", groupvars = c("name", "inst_size"))

ggplot(data_ef %>% filter(name != "Random"), aes(x = inst_size, y = ef)) +
  geom_point() +
  facet_wrap(~ name, ncol = 2) +
  ggtitle("Œrednia efektywnoœæ algorytmu dla danego rozmiaru instancji problemu") +
  xlab("Rozmiar instancji problemu") +
  ylab("Efektywnoœæ") +
  theme_bw()

ggplot(data_ef %>% filter(name == "Random"), aes(x = inst_size, y = ef)) +
  geom_point() +
  ggtitle("Œrednia efektywnoœæ - algorytm losowy") +
  xlab("Rozmiar instancji problemu") +
  ylab("Efektywnoœæ") +
  theme_bw()
```

Pierwsz¹ obserwacj¹ jest wyraŸnie gorsza efektywnoœæ algorytmu przeszukiwania losowego. Algorytmy *SA* i *TS*, a szczególnie ten pierwszy, wykazuj¹ wiêksz¹ efektywnoœæ dla wielu instancji testowych ni¿ przeszukiwanie lokalne, jednak przez szybciej rosn¹cy czas, ich efektywnoœæ spada dla wiêkszych instancji. Algorytm symulowanego wy¿arzania cechuje siê najmniejsz¹ zmiennoœci¹ efektywnoœci w zale¿noœci od instancji problemu (najmniejsze odchylenia od funkcji uzyskanej z regresji liniowej).

## Zale¿noœæ jakoœci rozwi¹zania koñcowego od jakoœci rozwi¹zania pocz¹tkowego (algorytmy przeszukiwania lokalnego)

Przeprowadzono eksperyment porównuj¹cy jakoœæ rozwi¹zania pocz¹tkowego z jakoœci¹ rozwi¹zania koñcowego w algorytmach przeszukiwania lokalnego. Wyniki zilustrowano poni¿szymi wykresami.

```{r init_result_relation}
data_init_result = read.csv2("gs_init_result.csv", col.names = c("name", "inst_name", "result", "init_result"), dec = ".")

for (i_name in unique(data_init_result$inst_name)) {
  instance_data <- data_init_result %>%
    filter(inst_name == i_name)
  
  print(ggplot(instance_data, aes(x = init_result, y = result)) +
    geom_point() +
    facet_grid(name ~ .) +
    ggtitle(i_name) +
    xlab("Jakoœæ rozwi¹zania pocz¹tkowego") +
    ylab("Jakoœæ rozwi¹zania koñcowego") +
    theme_bw()
  )
}
  
```

Z powy¿szych wykresów wynika, ¿e nie istnieje wyraŸna zale¿noœæ miêdzy jakoœci¹ rozwi¹zania pocz¹tkowego, a koñcowego. Pokazuj¹ one natomiast charakter badanych instancji problemu, w których okreœlone rozwi¹zania wystêpuj¹ czêœciej od innych (poziome "linie" na wykresach).

Brak zale¿noœci miêdzy jakoœci¹ pocz¹tkowego i koñcowego rozwi¹zania wynika ze z³o¿onego kszta³tu powierzchni rozwi¹zañ. Algorytmy przeszukiwania lokalnego znajduj¹ lokalne optimum, a nie mamy ¿adnej gwarancji, ¿e w okolicach dobrego rozwi¹zania bêdzie dobre optimum lokalne. Jedyn¹ gwarancj¹ dan¹ nam przez algorytmy przeszukiwania lokalnego jest fakt, ¿e rozwi¹zanie koñcowe bêdzie zawsze nie gorsze od pocz¹tkowego.

## Multi-random local search: Zale¿noœæ uzyskanego rozwi¹zania od liczby restartów

Dla dwóch algorytmów przeszukiwania lokalnego (*Greedy* i *Steepest*) przeprowadzono eksperyment sprawdzaj¹cy zale¿noœæ jakoœci uzyskanego rozwi¹zania od iloœci restartów (ponownych przeszukiwañ lokalnych zaczynaj¹cych od losowo wybranych punktów pocz¹tkowych). Wyniki przedstawiono na poni¿szych wykresach.

```{r multi_random}
data_multi_random = read.csv2("multi_random.csv", col.names = c("name", "inst_name", "result", "result_type", "iter_count"), dec = ".")

for (i_name in unique(data_multi_random$inst_name)) {
  instance_data <- data_multi_random %>%
    filter(inst_name == i_name)
  
  print(ggplot(instance_data, aes(x = iter_count, y = result, colour = result_type)) +
    geom_line() +
    facet_grid(name ~ .) +
    labs(title = i_name, x = "Liczba iteracji", y = "Jakoœæ zwróconego rozwi¹zania", color = "Rodzaj wyniku") +
    theme_bw()
  )
}
```

Zamieszczone wykresy pokazuj¹, ¿e algorytmy stosunkowo szybko (ju¿ po 2 -- 3 iteracjach) osi¹gaj¹ rozwi¹zanie bliskie koñcowemu (gdzie za koñcowe  uznajemy takie, które nie zmienia siê przez kilkadziesi¹t iteracji). Dalsze iteracje pomagaj¹ natomiast w coraz wolniejszym tempie poprawiaæ uzyskane rozwi¹zanie. Algorytm *Steepest* szybciej osi¹ga koñcowe rozwi¹zanie. Sugeruje to, ¿e efektywniej eksploruje on przestrzeñ. Wybieranie za ka¿dym razem najlepszego s¹siada mo¿e wiêc prowadziæ do wiêkszej ró¿norodnoœci znajdowanych optimów lokalnych po wielokrotnym uruchomieniu algorytmu. Wiêcej znalezionych optimów lokalnych zwiêksza natomiast prawdopodobieñstwo znalezienia optimum globalnego.

## Ocena podobieñstwa znajdywanych rozwi¹zañ lokalnie optymalnych

Okreœlono podobieñstwo miêdzy rozwi¹zaniami znalezionymi przez algorytmy przeszukiwania lokalnego. Podobieñstwo zosta³o zdefiniowane, jako liczba pozycji, na których rozwi¹zania maj¹ równe wartoœci. Przyk³adowo:

```{r results_similarity}
data_results_similarity <- read.csv2("results_similarity.csv", col.names = c("perm1", "perm2", "similarity", "score1", "score2", "inst_name"), dec = ".") %>%
  mutate(score_dif = abs(score1 - score2))

data_table <- data_results_similarity %>%
  select(perm1, perm2, similarity) %>%
  top_n(5)

kable(data_table, col.names = c("Permutacja 1", "Permutacja 2", "Podobieñstwo"))
```

Sporz¹dzono wykresy próbuj¹c zbadaæ zale¿noœæ miêdzy podobieñstwem, a ró¿nic¹ w jakoœci dla par rozwi¹zañ. Badanie przeprowadzono na dwóch niewielkich instancjach.

```{r results_similarity_graphs}
for (i_name in unique(data_results_similarity$inst_name)) {
  instance_data <- data_results_similarity %>%
    filter(inst_name == i_name)
  
  print(ggplot(instance_data, aes(x = similarity, y = score_dif)) +
    geom_point() +
    ggtitle(i_name) +
    xlab("Podobieñstwo rozwi¹zañ") +
    ylab("Ró¿nica jakoœci rozwi¹zañ") +
    theme_bw()
  )
}
```

Dla obu instancji problemu zaobserwowano zale¿noœæ miêdzy podobieñstwem rozwi¹zañ, a ró¿nic¹ ich jakoœci. Dla rozwi¹zañ ró¿ni¹cych siê znacznie od siebie, ró¿nica jakoœci wydaje siê byæ losowa (wystêpuj¹ zarówno pary o podobnej jakoœci, jak i bardzo odleg³e od siebie). Natomiast rozwi¹zania podobne do siebie czêœciej maj¹ niewielk¹ róŸnicê jakoœci.

## Wnioski

W ramach zadania zaimplementowano i przetestowano 6 algorytmów rozwi¹zuj¹cych problem QAP: *Random Search*, *Greedy Local Search*, *Steepest Local Search*, *Simulated Annealing*, *Tabu Search* oraz autorski algorytm heurystyczny. Do przeszukiwania przestrzeni rozwi¹zañ skorzystano z s¹siedztwa 2-OPT, które dla ka¿dego rozwi¹zania zwraca n<sup>2</sup> jego s¹siadów. 

W pierwszej kolejnoœci porównano liczbê wykonanych kroków oraz sprawdzonych s¹siadów przez algorytmy *Greedy LS* i *Steepest LS*. Okaza³o siê, ¿e jakkolwiek *Steepest* wykonuje znacznie mniej kroków dla ka¿dej badanej instancji, liczba sprawdzonych przez niego s¹siadów w pe³nej iteracji jest zazwyczaj wy¿sza od "konkurenta".

Wzglêdna odleg³oœæ znalezionego rozwi¹zania od optimum globalnego jest niezale¿na od wielkoœci instancji. Ró¿nice w jakoœci rozwi¹zania wynikaj¹ raczej z "trudnoœci" instancji problemu - stopnia skomplikowania przestrzeni rozwi¹zañ.

Czas wykonywania algorytmów roœnie wraz ze wzrostem wielkoœci instancji. Jest to spodziewany wniosek, jednak nale¿y zauwa¿yæ, ¿e od tej regu³y s¹ wyj¹tki i d³ugoœæ permutacji nie jest jedynym kryterium determinuj¹cym czas wykonywania algorytmu. Czas wykonywania algorytmu dla wszystkich testowanych algorytmów zdaje siê rosn¹æ wielomianowo, jednak znacznie szybciej dla algorytmów *Simulated Annealing* i *Tabu Search* (wy¿szy stopieñ wielomianu).

Najbardziej stabilny czas wykonywania wykazuje *Steepest Local Search*, co jest zrozumia³e bior¹c pod uwagê, ¿e w ka¿dym kroku przeszukuje ca³e dostêpne s¹siedztwo (które ma równ¹ licznoœæ w ka¿dym punkcie przestrzeni rozwi¹zañ).

TODO: Opisaæ niestabilnoœæ czasu wykonywania *SA* i *TS*.

Porównanie czasu wykonywania algorytmów *Greedy* i *Steepest* prowadzi do wniosku, ¿e ¿aden z nich nie jest jednoznacznie lepszy od drugiego. Zawsze znajdzie siê instancja, dla której *Greedy* zakoñczy siê szybciej oraz taka, dla której to *Steepest* osi¹gnie lepszy czas.

Zaproponowano miarê efektywnoœci iteracji algorytmów. Uzale¿niono j¹ od czasu trwania iteracji i jakoœci znalezionego rozwi¹zania (odleg³oœci od rozwi¹zania optymalnego). Uzyskane wyniki pokazuj¹ lepsze wyniki algorytmów *SA* i *TS*, jednak dla du¿ych instancji problemu, znaczny czas wykonywania prowadzi do niskiej oceny efektywnoœci.

Nie mo¿na wskazaæ wyra¿nej zale¿noœci miêdzy jakoœci¹ rozwi¹zania pocz¹tkowego, a koñcowego w algorytmach przeszukiwania lokalnego. Jedyn¹ pewn¹ zale¿noœci¹ jest, ¿e zwrócone rozwi¹zanie bêdzie siê charakteryzowa³o jakoœci¹ nie gorsz¹ od pocz¹tkowego.

*Multi-random Local Search* (wielokrotne uruchamianie przeszukiwania lokalnego w losowych punktach) stanowi bardzo sprawne ulepszenie algorytmów LS. Z przeprowadzonych eksperymentów wynika, ¿e dobre rozwi¹zanie osi¹gane jest stosunkowo szybko. Wielokrotne uruchamianie *LS* pozwala na znalezienie wiêkszej liczby optimów lokalnych, a w konsekwencji zwiêksza szansê znalezienia rozwi¹zania optymalnego globalnie.

Na koniec oceniono podobieñstwo znajdowanych przez *LS* rozwi¹zañ oraz podjêto próbê znalezienia relacji miêdzy podobieñstwem rozwi¹zañ, a ró¿nic¹ ich jakoœci. Wykorzystano miarê równ¹ liczbie pozycji, na których permutacje maj¹ równe wartoœci. Zauwa¿ono, ¿e dla niektórych instancji mo¿e wystêpowaæ wyraŸna zale¿noœæ miêdzy podobieñstwem rozwi¹zañ, a ró¿nic¹ ich jakoœci.

## Napotkane trudnoœci

Przy wykonywaniu zadania nie natrafiono na ¿adne istotne trudnoœci.

