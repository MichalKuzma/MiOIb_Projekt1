---
title: "Algorytmy rozwi¹zuj¹ce problem QAP"
author: "Micha³ KuŸma i Micha³ Biernacki"
date: "11 listopada 2016"
output: 
  html_document: 
    keep_md: yes
---

```{r setup, include=FALSE}
library(knitr)
library(dplyr)
library(ggplot2)
opts_chunk$set(echo = FALSE, warning = FALSE, tidy = TRUE, message = FALSE)
```

```{r func_def}
## Summarizes data.
## Gives count, mean, standard deviation, standard error of the mean, and confidence interval (default 95%).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summariezed
##   groupvars: a vector containing names of columns that contain grouping variables
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {
  
  library(plyr)

    # New version of length which can handle NA's: if na.rm==T, don't count them
    length2 <- function (x, na.rm=FALSE) {
        if (na.rm) sum(!is.na(x))
        else       length(x)
    }

    # This does the summary. For each group's data frame, return a vector with
    # N, mean, and sd
    datac <- ddply(data, groupvars, .drop=.drop,
      .fun = function(xx, col) {
        c(N    = length2(xx[[col]], na.rm=na.rm),
          mean = mean   (xx[[col]], na.rm=na.rm),
          sd   = sd     (xx[[col]], na.rm=na.rm),
          min = min     (xx[[col]], na.rm=na.rm)
        )
      },
      measurevar
    )

    # Rename the "mean" column    
    datac <- rename(datac, c("mean" = measurevar))

    datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean

    # Confidence interval multiplier for standard error
    # Calculate t-statistic for confidence interval: 
    # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
    ciMult <- qt(conf.interval/2 + .5, datac$N-1)
    datac$ci <- datac$se * ciMult

    
    library(dplyr)
    return(datac)
}
```

```{r load_data}
data <- read.csv2("qap_algorithms.csv", col.names = c("name", "result", "opt_result", "perm", "opt_perm", "time", "inst_size", "inst_name", "init_perm", "rev_neigh", "steps_count"),
                  dec = ".")
data <- data %>%
  mutate(result_dist = (result - opt_result) / opt_result)
```

## Opis problemu

QAP (Quadratic assignment problem) reprezentuje nastêpuj¹ce zadanie:

*Dane s¹ zbiory n lokalizacji i n oœrodków. Ka¿da para lokacji znajduje siê w okreœlonej odleg³oœci od siebie, a dla ka¿dej pary oœrodków znany jest przep³yw. Celem jest takie przypisanie oœrodków do lokalizacji, aby zminimalizowaæ sumê iloczynów odleg³oœci i przep³ywów.*

Problem wykorzystywany jest czêsto do zamodelowania zadania rozmieszczenia fabryk (oœrodków) w zestawie znanych lokalizacji. Jako przep³ywy podane s¹ wówczas interakcje, w jakie fabryki wchodz¹ wzajemnie (transport surowców, etc.).

Poniewa¿ problem nale¿y do grupy NP-trudnych, nie jest znany algorytm, który pozwoli³by na znalezienie dok³adnego rozwi¹zania w czasie wielomianowym. W celu osi¹gniêcia zadowalaj¹cych wyników czasowych uzyskuj¹c dobre rozwi¹zanie, wykorzystuje siê algorytmy heurystyczne i metaheurystyki.

## Operator s¹siedztwa

W projekcie korzystano z operatora s¹siedztwa 2-OPT, który dla ka¿dej permutacji zwraca s¹siedztwo z³o¿one ze wszystkich permutacji uzyskanych przez zamianê dwóch pozycji miejscami.

Wykorzystanie tego operatora sprawia, ¿e wielkoœæ s¹siedztwa ka¿dej permutacji wynosi n<sup>2</sup> (gdzie n to d³ugoœæ permutacji).

## Krótki opis zaimplementowanych algorytmów

### Random Search

Algorytm przeszukiwania losowego (Random Search) jest najprostszym z wykorzystanych w projekcie. Przez okreœlony czas losuje on rozwi¹zania i na koniec zwraca najlepsze z nich. Parametr czasowy stanowi jedyne kryterium stopu algorytmu.

### Local Search

Algorytm przeszukiwania lokalnego (Local Search) wyszukuje lepsze rozwi¹zania w zbiorach s¹siedztwa a¿ do osi¹gniêcia optimum lokalnego. Nie daje jednak ¿adnej gwarancji odnalezienia optimum globalnego. Algorytm zosta³ zaimplementowany w dwóch wersjach ró¿ni¹cych siê sposobem wyboru s¹siada, do którego algorytm powinien przejœæ.

- *Greedy Local Search* wybiera pierwszego s¹siada, który jest lepszy od obecnie rozpatrywanego rozwi¹zania.
- *Steepest Local Search* przeszukuje ca³e s¹siedztwo wybieraj¹c najlepszego s¹siada i przechodzi do niego, jeœli jest lepszy od obecnego rozwi¹zania.

Przeprowadzono eksperyment zliczaj¹cy, ilu s¹siadów oceniaj¹ obie wersje algorytmu, oraz ile kroków robi¹. Wyniki przedstawiono na poni¿szych wykresach. W celu lepszej czytelnoœci wykresów, wybrano instancje o wielkoœci mniejszej, ni¿ $n = 30$.

```{r gs_compare}
# Neighbours count
data_results <- data %>%
  filter(name == "Greedy" | name == "Steepest", inst_size < 30) %>%
  summarySE(measurevar = "rev_neigh", groupvars = c("name", "inst_size"))

ggplot(data_results, aes(x = inst_size, y = rev_neigh)) +
  geom_errorbar(aes(ymin = rev_neigh-se, ymax = rev_neigh+se), width=.1) +
  geom_point() +
  facet_wrap(~ name, ncol = 2) +
  ggtitle("Liczba s¹siadów ocenionych przez algorytm w jednej iteracji") +
  xlab("Rozmiar instancji problemu") +
  ylab("Liczba ocenionych s¹siadów") +
  theme_bw()

# Time
data_results <- data %>%
  filter(name == "Greedy" | name == "Steepest", inst_size < 30) %>%
  summarySE(measurevar = "steps_count", groupvars = c("name", "inst_size"))

ggplot(data_results, aes(x = inst_size, y = steps_count)) +
  geom_errorbar(aes(ymin = steps_count-se, ymax = steps_count+se), width=.1) +
  geom_point() +
  facet_wrap(~ name, ncol = 2) +
  ggtitle("Liczba kroków wykonanych przez algorytm w jednej iteracji") +
  xlab("Rozmiar instancji problemu") +
  ylab("Liczba wykonanych kroków") +
  theme_bw()
```

Powy¿sze wykresy pokazuj¹, ¿e w pe³nej iteracji *Steepest* wykonuje znacznie mniej kroków od algorytmu *Greedy*, jednak poniewa¿ za ka¿dym razem sprawdza wszystkich mo¿liwych s¹siadów, liczba ocenionych przez niego rozwi¹zañ jest wiêksza dla wiêkszoœci instancji problemu. Algorytm *Greedy* wykazuje du¿¹ niestabilnoœæ zarówno w liczbie wykonanych kroków, jak i ocenionych s¹siadów (Dla wiêkszoœci instancji odchylenia s¹ wiêksze, ni¿ w *Steepest*).

### Heurystyka

Algorytm heurystyczny buduje rozwi¹zanie w oparciu o predefiniowane regu³y, które zgodnie z za³o¿eniem maj¹ prowadziæ do dobrego wyniku. Zapproponowana w projekcie heurystyka dzia³a analogicznie do sortowania b¹belkowego. Po wylosowaniu permutacji startowej wybierany jest najkorzystniejszy w obecnym krajobrazie element na kolejne pozycje (0, 1, 2, ...).

```
  solution = randomSolution()
  value = solution.getValue()
  
  for (i = 0; i < n; i++) {
    for (j = i + 1; j < n; j++) {
      changeValue = valueOfChangingItemsAtPositions(i, j)
      if (changeValue < 0) {
        changeElementsAtPositions(i, j)
        value += changeValue
      }
    }
  }
```

## Porównanie odleg³oœci od optimum rozwi¹zañ uzyskanych przez badane algorytmy

Do okreœlenia odleg³oœci od optimum globalnego wykorzystano miarê opisan¹ wzorem:

$dist = \frac{Opt_{L} - Opt_{G}}{Opt_{G}}$

Dla ka¿dej badanej instancji wykonano 10 pomiarów. Porównano wyniki œrednie, oraz najlepsze. Wyniki pomiarów zosta³y przedstawione na poni¿szych wykresach.

```{r results_compare}
data_results <- data %>%
  filter(inst_size >= 40) %>%
  summarySE(measurevar = "result_dist", groupvars = c("name", "inst_size"))

ggplot(data_results, aes(x = inst_size, y = result_dist)) +
  geom_errorbar(aes(ymin = result_dist-se, ymax = result_dist+se), width=.1) +
  geom_point() +
  facet_wrap(~ name, ncol = 2) +
  ggtitle("Œrednia odleg³oœæ uzyskanego przez algorytm rozwi¹zania od optimum") +
  xlab("Rozmiar instancji problemu") +
  ylab("Odleg³oœæ od optimum") +
  geom_smooth(method = "lm") +
  theme_bw()
```

Zaobserwowaæ mo¿na wysok¹ niestabilnoœæ uzyskanych wyników dla niektórych instancji problemu (du¿e odchylenia standardowe dla ka¿dego algorytmu). Mo¿e to byæ spowodowane skomplikowan¹ powierzchni¹ rozwi¹zañ.


```{r best_results_compare}
ggplot(data_results, aes(x = inst_size, y = min)) +
  geom_point() +
  facet_wrap(~ name, ncol = 2) +
  ggtitle("Minimalna odleg³oœæ uzyskanego przez algorytm rozwi¹zania od optimum") +
  xlab("Rozmiar instancji problemu") +
  ylab("Odleg³oœæ od optimum") +
  geom_smooth(method = "lm") +
  theme_bw()
```

Po rozpatrzeniu najlepszego zamiast œredniego rozwi¹zania, charakter malej¹cy jest ju¿ s³abiej zauwa¿alny. Najmniejsze odleg³oœci wystêpuj¹ dla instancji najmniejszych i najwiêkszych, podczas gdy instancje o poœredniej wielkoœci maj¹ najwiêksz¹ wzglêdn¹ odleg³oœæ od optimum.

Algorytmy *Greedy* i *Steepest* osi¹gaj¹ bardzo podobne œrednie rozwi¹zania. Zaproponowana heurystyka zwraca nieznacznie gorsze rozwi¹zania od algorytmów przeszukiwania lokalnego, natomiast *Random* osi¹ga rozwi¹zania daleko gorsze od pozosta³ych (poza prostymi instancjami).

Metod¹ regresji liniowej, wyznaczono zale¿noœci miêdzy wielkoœci¹ instancji, a wzglêdn¹ odleg³oœci¹ rozwi¹zania od optimum. Algorytm *Random* zdaje siê wykazywaæ delikatn¹ zale¿noœæ malej¹c¹ (im wiêksza instancja, tym mniejsza wzglêdna odleg³oœæ od optimum). Pozosta³e algorytmy nie wykazuj¹ ¿adnej relacji miêdzy tymi wielkoœciami.

## Porównanie czasów wykonywania algorytmów

Poniewa¿ warunkiem stopu algorytmu *Random* jest up³yniêcie okreœlonego czasu (œciœle - œredniego czasu wykonywania *Local Search*), jego wykresy zosta³y pominiête.

```{r times_compare}
data_times <- data %>%
  filter(inst_size >= 40, name != "Random") %>%
  summarySE(measurevar = "time", groupvars = c("name", "inst_size"))

ggplot(data_times, aes(x = inst_size, y = time)) +
  geom_errorbar(aes(ymin = time-se, ymax = time+se), width=.1) +
  geom_point() +
  facet_wrap(~ name, ncol = 2) +
  ggtitle("Œredni czas dzia³ania algorytmu w milisekundach") +
  xlab("Rozmiar instancji problemu") +
  ylab("Czas dzia³ania algorytmu") +
  geom_smooth(method = "lm") +
  theme_bw()
```

```{r best_times_compare}
ggplot(data_times, aes(x = inst_size, y = min)) +
  geom_point() +
  facet_wrap(~ name, ncol = 2) +
  ggtitle("Najkrótszy czas dzia³ania algorytmu w milisekundach") +
  xlab("Rozmiar instancji problemu") +
  ylab("Czas dzia³ania algorytmu") +
  geom_smooth(method = "lm") +
  theme_bw()
```

Przedstawione powy¿ej wykresy czasu trwania iteracji algorytmów pokazuj¹ wzrost czasu trwania algorytmu wraz ze wzrostem wielkoœci instancji (czego mo¿na siê by³o spodziewaæ). Wykresy œredniego czasu dzia³ania pokazuj¹ rosn¹c¹ niestabilnoœæ mierzonego czasu (która nie jest jednak zale¿na jedynie od wielkoœci instancji). Œredni czas wykonywania algorytmu lokalnego przeszukiwania w obu wersjach (*Greedy* i *Steepest*) jest podobny dla ka¿dej testowanej instancji problemu. Niektóre instancje rozwi¹zywane s¹ szybciej przy u¿yciu jednego z nich, inne - drugiego. 

## Zale¿noœæ jakoœci rozwi¹zania koñcowego od jakoœci rozwi¹zania pocz¹tkowego (algorytmy przeszukiwania lokalnego)

Przeprowadzono eksperyment porównuj¹cy jakoœæ rozwi¹zania pocz¹tkowego z jakoœci¹ rozwi¹zania koñcowego w algorytmach przeszukiwania lokalnego. Wyniki zilustrowano poni¿szymi wykresami.

```{r init_result_relation}
data_init_result = read.csv2("gs_init_result.csv", col.names = c("name", "inst_name", "result", "init_result"), dec = ".")

for (i_name in unique(data_init_result$inst_name)) {
  instance_data <- data_init_result %>%
    filter(inst_name == i_name)
  
  print(ggplot(instance_data, aes(x = init_result, y = result)) +
    geom_point() +
    facet_grid(name ~ .) +
    ggtitle(i_name) +
    xlab("Jakoœæ rozwi¹zania pocz¹tkowego") +
    ylab("Jakoœæ rozwi¹zania koñcowego") +
    theme_bw()
  )
}
  
```

Z powy¿szych wykresów wynika, ¿e nie istnieje wyraŸna zale¿noœæ miêdzy jakoœci¹ rozwi¹zania pocz¹tkowego, a koñcowego. Pokazuj¹ one natomiast charakter badanych instancji problemu, w których okreœlone rozwi¹zania wystêpuj¹ czêœciej od innych (poziome "linie" na wykresach).

Brak zale¿noœci miêdzy jakoœci¹ pocz¹tkowego i koñcowego rozwi¹zania wynika ze z³o¿onego kszta³tu powierzchni rozwi¹zañ. Algorytmy przeszukiwania lokalnego znajduj¹ lokalne optimum, a nie mamy ¿adnej gwarancji, ¿e w okolicach dobrego rozwi¹zania bêdzie dobre optimum lokalne. Jedyn¹ gwarancj¹ dan¹ nam przez algorytmy przeszukiwania lokalnego jest fakt, ¿e rozwi¹zanie koñcowe bêdzie zawsze nie gorsze od pocz¹tkowego.

## Multi-random local search: Zale¿noœæ uzyskanego rozwi¹zania od liczby restartów

Dla dwóch algorytmów przeszukiwania lokalnego (*Greedy* i *Steepest*) przeprowadzono eksperyment sprawdzaj¹cy zale¿noœæ jakoœci uzyskanego rozwi¹zania od iloœci restartów (ponownych przeszukiwañ lokalnych zaczynaj¹cych od losowo wybranych punktów pocz¹tkowych). Wyniki przedstawiono na poni¿szych wykresach.

```{r multi_random}
data_multi_random = read.csv2("multi_random.csv", col.names = c("name", "inst_name", "result", "iter_count"), dec = ".")

for (i_name in unique(data_multi_random$inst_name)) {
  instance_data <- data_multi_random %>%
    filter(inst_name == i_name)
  
  print(ggplot(instance_data, aes(x = iter_count, y = result)) +
    geom_line() +
    facet_grid(name ~ .) +
    ggtitle(i_name) +
    xlab("Liczba iteracji") +
    ylab("Jakoœæ zwróconego rozwi¹zania") +
    theme_bw()
  )
}
```

Zamieszczone wykresy pokazuj¹, ¿e algorytmy stosunkowo szybko (ju¿ po 2 - 3 iteracjach) osi¹gaj¹ rozwi¹zanie bliskie koñcowemu (gdzie za koñcowe  uznajemy takie, które nie zmienia siê przez kilkadziesi¹t iteracji). Dalsze iteracje pomagaj¹ natomiast w coraz wolniejszym tempie poprawiaæ uzyskane rozwi¹zanie. Algorytm *Steepest* szybciej osi¹ga koñcowe rozwi¹zanie. Sugeruje to, ¿e efektywniej eksploruje on przestrzeñ. Wybieranie za ka¿dym razem najlepszego s¹siada mo¿e wiêc prowadziæ do wiêkszej ró¿norodnoœci znajdowanych optimów lokalnych po wielokrotnym uruchomieniu algorytmu. Wiêcej znalezionych optimów lokalnych zwiêksza natomiast prawdopodobieñstwo znalezienia optimum globalnego.

## Ocena podobieñstwa znajdywanych rozwi¹zañ lokalnie optymalnych

Poni¿ej znajduj¹ siê listy znalezionych rozwi¹zañ dla dwóch instancji

```{r result_compare, results="asis"}
data_result_compare <- data %>%
  filter(inst_name == "data/qapdata/had12" | inst_name == "data/qapdata/nug14",
         name == "Steepest")

list_template <- "
- %s"
header_template <- "

### %s
"

for (i_name in unique(data_result_compare$inst_name)) {
  cat(sprintf(header_template, i_name))
  
  data_instance <- data_result_compare %>%
    filter(inst_name == i_name)
  for (res in unique(data_instance$perm)) {
    cat(sprintf(list_template, res))
  }
}
```