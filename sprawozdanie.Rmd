---
title: "Algorytmy rozwi�zuj�ce problem QAP"
author: "Micha�� Ku�ma i Micha�� Biernacki"
date: "11 listopada 2016"
output:
  html_document:
    keep_md: yes
  pdf_document: default
---

```{r setup, include=FALSE}
library(knitr)
library(dplyr)
library(ggplot2)
opts_chunk$set(echo = FALSE, warning = FALSE, tidy = TRUE, message = FALSE)
```

```{r func_def}
## Summarizes data.
## Gives count, mean, standard deviation, standard error of the mean, and confidence interval (default 95%).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summariezed
##   groupvars: a vector containing names of columns that contain grouping variables
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {
  
  library(plyr)

    # New version of length which can handle NA's: if na.rm==T, don't count them
    length2 <- function (x, na.rm=FALSE) {
        if (na.rm) sum(!is.na(x))
        else       length(x)
    }

    # This does the summary. For each group's data frame, return a vector with
    # N, mean, and sd
    datac <- ddply(data, groupvars, .drop=.drop,
      .fun = function(xx, col) {
        c(N    = length2(xx[[col]], na.rm=na.rm),
          mean = mean   (xx[[col]], na.rm=na.rm),
          sd   = sd     (xx[[col]], na.rm=na.rm),
          min = min     (xx[[col]], na.rm=na.rm)
        )
      },
      measurevar
    )

    # Rename the "mean" column    
    datac <- rename(datac, c("mean" = measurevar))

    datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean

    # Confidence interval multiplier for standard error
    # Calculate t-statistic for confidence interval: 
    # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
    ciMult <- qt(conf.interval/2 + .5, datac$N-1)
    datac$ci <- datac$se * ciMult

    
    library(dplyr)
    return(datac)
}
```

```{r load_data}
data <- read.csv2("qap_algorithms.csv", col.names = c("name", "result", "opt_result", "perm", "opt_perm", "time", "inst_size", "inst_name", "init_perm", "rev_neigh", "steps_count"),
                  dec = ".")
data <- data %>%
  mutate(result_dist = (result - opt_result) / opt_result)
```

## Opis problemu

QAP (Quadratic assignment problem) reprezentuje nast�puj�ce zadanie:

*Dane s� zbiory n lokalizacji i n o�rodk�w. Ka�da para lokacji znajduje si� w okre�lonej odleg�o�ci od siebie, a dla ka�dej pary o�rodk�w znany jest przep�yw. Celem jest takie przypisanie o�rodk�w do lokalizacji, aby zminimalizowa� sum� iloczyn�w odleg�o�ci i przep�yw�w.*

Problem wykorzystywany jest cz�sto do zamodelowania zadania rozmieszczenia fabryk (o�rodk�w) w zestawie znanych lokalizacji. Jako przep�ywy podane s� w�wczas interakcje, w jakie fabryki wchodz� wzajemnie (transport surowc�w, etc.).

Poniewa� problem nale�y do grupy NP-trudnych, nie jest znany algorytm, kt�ry pozwoli�by na znalezienie dok�adnego rozwi�zania w czasie wielomianowym. W celu osi�gni�cia zadowalaj�cych wynik�w czasowych uzyskuj�c dobre rozwi�zanie, wykorzystuje si� algorytmy heurystyczne i metaheurystyki.

## Operator s�siedztwa

W projekcie korzystano z operatora s�siedztwa 2-OPT, kt�ry dla ka�dej permutacji zwraca s�siedztwo z�o�one ze wszystkich permutacji uzyskanych przez zamian� dw�ch pozycji miejscami.

Wykorzystanie tego operatora sprawia, �e wielko�� s�siedztwa ka�dej permutacji wynosi n<sup>2</sup> (gdzie n to d�ugo�� permutacji).

## Kr�tki opis zaimplementowanych algorytm�w

### Random Search

Algorytm przeszukiwania losowego (Random Search) jest najprostszym z wykorzystanych w projekcie. Przez okre�lony czas losuje on rozwi�zania i na koniec zwraca najlepsze z nich. Parametr czasowy stanowi jedyne kryterium stopu algorytmu.

### Local Search

Algorytm przeszukiwania lokalnego (Local Search) wyszukuje lepsze rozwi�zania w zbiorach s�siedztwa a� do osi�gni�cia optimum lokalnego. Nie daje jednak �adnej gwarancji odnalezienia optimum globalnego. Algorytm zosta� zaimplementowany w dw�ch wersjach r��ni�cych si� sposobem wyboru s�siada, do kt�rego algorytm powinien przej��.

- *Greedy Local Search* wybiera pierwszego s�siada, kt�ry jest lepszy od obecnie rozpatrywanego rozwi�zania.
- *Steepest Local Search* przeszukuje ca�e s�siedztwo wybieraj�c najlepszego s�siada i przechodzi do niego, je�li jest lepszy od obecnego rozwi�zania.

Przeprowadzono eksperyment zliczaj�cy, ilu s�siad�w oceniaj� obie wersje algorytmu, oraz ile krok�w robi�. Wyniki przedstawiono na poni�szych wykresach. W celu lepszej czytelno�ci wykres�w, wybrano instancje o wielko�ci mniejszej, ni� $n = 30$.

```{r gs_compare}
# Neighbours count
data_results <- data %>%
  filter(name == "Greedy" | name == "Steepest", inst_size < 30) %>%
  summarySE(measurevar = "rev_neigh", groupvars = c("name", "inst_size"))

ggplot(data_results, aes(x = inst_size, y = rev_neigh)) +
  geom_errorbar(aes(ymin = rev_neigh-se, ymax = rev_neigh+se), width=.1) +
  geom_point() +
  facet_wrap(~ name, ncol = 2) +
  ggtitle("Liczba s�siad�w ocenionych przez algorytm w jednej iteracji") +
  xlab("Rozmiar instancji problemu") +
  ylab("Liczba ocenionych s�siad�w") +
  theme_bw()

# Time
data_results <- data %>%
  filter(name == "Greedy" | name == "Steepest", inst_size < 30) %>%
  summarySE(measurevar = "steps_count", groupvars = c("name", "inst_size"))

ggplot(data_results, aes(x = inst_size, y = steps_count)) +
  geom_errorbar(aes(ymin = steps_count-se, ymax = steps_count+se), width=.1) +
  geom_point() +
  facet_wrap(~ name, ncol = 2) +
  ggtitle("Liczba krok�w wykonanych przez algorytm w jednej iteracji") +
  xlab("Rozmiar instancji problemu") +
  ylab("Liczba wykonanych krok�w") +
  theme_bw()
```

Powy�sze wykresy pokazuj�, �e w pe�nej iteracji *Steepest* wykonuje znacznie mniej krok�w od algorytmu *Greedy*, jednak poniewa� za ka�dym razem sprawdza wszystkich mo�liwych s�siad�w, liczba ocenionych przez niego rozwi�za� jest wi�ksza dla wi�kszo�ci instancji problemu. Algorytm *Greedy* wykazuje du�� niestabilno�� zar�wno w liczbie wykonanych krok�w, jak i ocenionych s�siad�w (Dla wi�kszo�ci instancji odchylenia s� wi�ksze, ni� w *Steepest*).

### Heurystyka

Algorytm heurystyczny buduje rozwi�zanie w oparciu o predefiniowane regu�y, kt�re zgodnie z za�o�eniem maj� prowadzi� do dobrego wyniku.Zaproponowana w projekcie heurystyka dzia�a na bardzo naiwnym za�o�eniu, �e ka�dy element w permutacji ma swoj� jedn�, najbardziej optymaln� pozycj� (w tej permutacji), i zawsze przesuwaj�c ten element bli�ej tego miejsca zwi�kszamy warto�� funkcji celu (zmniejszamy koszta). W takim przypadku problem ten sprowadza si� do problemu sortowania. Heurystyka rozwi�zuje to dalej stosuj�c podej�cie analogiczne, jak algorytm sortowania b�belkowego, dzi�ki czemu z�o�ono�� obliczeniowa wynosi O(n<sup>2</sup>), gdzie n to rozmiar permutacji.
Pocz�tkowa permutacja jest tworzona w spos�b losowy, dzi�ki czemu heurystyka mo�e ka�dorazowo dla jednej instancji problemu zwraca� r��ne wyniki.

```
  solution = randomSolution()
  value = solution.getValue()
  
  for (i = 0; i < n; i++) {
    for (j = i + 1; j < n; j++) {
      changeValue = valueOfChangingItemsAtPositions(i, j)
      if (changeValue < 0) {
        changeElementsAtPositions(i, j)
        value += changeValue
      }
    }
  }
```

### Simulated Annealing

Algorytm symulowanego wy�arzania (simulated annealing) przeszukuje przestrze� rozwi�za� poprzez przechodzenie do losowego s�siada, kt�ry poprawia, a przynajmniej za mocno nie pogarsza warto�ci funkcji celu. To czy algorytm przejdzie do pogarszaj�cego s�siada zale�y od parametru temperatury. Pocz�tkowo ustawiana jest taka warto�� temperatury, by 95% losowych s�siad�w by�o akceptowanych, a nast�pnie, co okre�lon� ilo�� krok�w ([wielko�� instancji]<sub>2</sub>) jest on zmniejszany (w naszym zastosowaniu, jest temperatura mno�ona razy 0.95, bo taka warto�� dawa�a najlepsze rezultaty w stosunku do czasu przetwarzania).
Algorytm ko�czy swoje dzia�anie, gdy nie znajdzie akceptowalnego s�siada w okre�lonej liczbie pr�b ([wielko�� instancji]<sub>2</sub>), lub gdy temperatura osi�gnie tak� warto��, �e prawdopodobie�stwo akceptacji ruch�w pogarszaj�cych b�dzie wynosi�o 0%.

### Tabu Search

Algorytm przeszukiwania tabu (tabu search) w ka�dym etapie wybiera list� kilku najlepszych mo�liwych ruch�w (o rozmiarze [wielko�� instancji]/10). Dalej z tej listy wybierane s� kolejno najlepsze ruchy w stosunku do aktualnego stanu, a� lista nie zostanie pusta. Ruch odrzucany jest na 2 sposoby:

- Gdy strata jest zbyt du�a, w tym z czasem dzia�ania akceptowalna strata jest coraz mniejsza. Analogicznie jak temperatura w algorytmie symulowanego wy�arzania.
- Gdy ruch znajduje si� na li�cie tabu, akceptowany jest tylko je�eli polepsza warto�� funkcji celu.

Lista tabu ma na celu zablokowanie "cofania" si� - s� na niej ruchy przeciwne (takie kt�re przywr�ci�yby stan) do ruch�w ostatnio wykonanych. W naszej implementacji ma ona rozmiar nie wi�kszy ni� [wielko�� instancji]/4. Po wykonaniu ka�dego ruchu, ruch do niego przeciwny jest dodawany do listy, a najstarszy na li�cie jest odrzucany.
Algorytm ko�czy swoje dzia�anie w podobny spos�b jak algorytm symulowanego wy�arzania - gdy przez du�� liczb� operacji ([wielko�� instancji]<sub>2</sub>) nie zostanie wykonany �aden ruch, lub gdy prawdopodobie�stwo akceptacji ruch�w pogarszaj�cych b�dzie wynosi�o 0%.

## Por�wnanie odleg�o�ci od optimum rozwi�za� uzyskanych przez badane algorytmy

Do okre�lenia odleg�o�ci od optimum globalnego wykorzystano miar� opisan� wzorem:

$dist = \frac{Opt_{L} - Opt_{G}}{Opt_{G}}$

Dla ka�dej badanej instancji wykonano 10 pomiar�w. Por�wnano wyniki �rednie oraz najlepsze. Wyniki pomiar�w zosta�y przedstawione na poni�szych wykresach.

```{r results_compare}
data_results <- data %>%
  filter(inst_size < 100) %>%
  summarySE(measurevar = "result_dist", groupvars = c("name", "inst_size"))

ggplot(data_results %>% filter(name != "Random"), aes(x = inst_size, y = result_dist)) +
  geom_errorbar(aes(ymin = result_dist-se, ymax = result_dist+se), width=.1) +
  geom_point() +
  facet_wrap(~ name, ncol = 2) +
  ggtitle("�rednia odleg�o�� uzyskanego przez algorytm rozwi�zania od optimum") +
  xlab("Rozmiar instancji problemu") +
  ylab("Odleg�o�� od optimum") +
  theme_bw()

ggplot(data_results %>% filter(name == "Random"), aes(x = inst_size, y = result_dist)) +
  geom_errorbar(aes(ymin = result_dist-se, ymax = result_dist+se), width=.1) +
  geom_point() +
  ggtitle("�rednia odleg�o�� uzyskanego przez algorytm losowy rozwi�zania od optimum") +
  xlab("Rozmiar instancji problemu") +
  ylab("Odleg�o�� od optimum") +
  theme_bw()
```

```{r best_results_compare}
ggplot(data_results %>% filter(name != "Random"), aes(x = inst_size, y = min)) +
  geom_point() +
  facet_wrap(~ name, ncol = 2) +
  ggtitle("Minimalna odleg�o�� uzyskanego przez algorytm rozwi�zania od optimum") +
  xlab("Rozmiar instancji problemu") +
  ylab("Odleg�o�� od optimum") +
  theme_bw()

ggplot(data_results %>% filter(name == "Random"), aes(x = inst_size, y = min)) +
  geom_point() +
  ggtitle("Minimalna odleg�o�� od optimum - algorytm losowy") +
  xlab("Rozmiar instancji problemu") +
  ylab("Odleg�o�� od optimum") +
  theme_bw()
```

Ze wzgl�du na diametralnie gorsze wyniki, dla lepszej czytelno�ci, wykres algorytmu *Random Search* przedstawiono na odr�bnej skali.

Zaobserwowa� mo�na wysok� niestabilno�� uzyskanych wynik�w dla niekt�rych instancji problemu (du�e odchylenia standardowe dla ka�dego algorytmu). Mo�e to by� spowodowane skomplikowan� przestrzeni� rozwi�za�. 

Metod� regresji liniowej wyznaczono zale�no�ci mi�dzy wielko�ci� instancji, a wzgl�dn� odleg�o�ci� rozwi�zania od optimum. Wszystkie badane algorytmy zdaj� si� wykazywa� niezale�no�� jako�ci rozwi�zania ko�cowego (odleg�o�ci od optimum) od wielko�ci instancji. R��nice w jako�ci ko�cowego rozwi�zania powodowane s� raczej r��nym stopniem skomplikowania powierzchni rozwi�za� dla danych instancji.

Algorytmy *Greedy* i *Steepest* osi�gaj� bardzo podobne �rednie rozwi�zania. Zaproponowana heurystyka zwraca nieznacznie gorsze rozwi�zania od algorytm�w przeszukiwania lokalnego, natomiast *Random* osi�ga rozwi�zania daleko gorsze od pozosta�ych (poza prostymi instancjami).

Algorytmy Simulated Annealing (SA) i Tabu Search (TS) wykazuj� wi�ksz� niezale�no�� od stopnia skomplikowania instancji (mniejsze odchylenia od wyliczonej funkcji liniowej), szczeg�lnie uwzgl�dniaj�c rozwi�zanie najlepsze ze znalezionych

## Por�wnanie czas�w wykonywania algorytm�w

Poniewa� warunkiem stopu algorytmu *Random* jest up�yni�cie okre�lonego czasu (�redniego czasu wykonywania *Local Search*), jego wykresy zosta�y pomini�te.

```{r times_compare}
data_times <- data %>%
  filter(name != "Random", inst_size < 100) %>%
  summarySE(measurevar = "time", groupvars = c("name", "inst_size"))

ggplot(data_times, aes(x = inst_size, y = time)) +
  geom_errorbar(aes(ymin = time-se, ymax = time+se), width=.1) +
  geom_point() +
  facet_wrap(~ name, ncol = 2) +
  ggtitle("�redni czas dzia�ania algorytmu w milisekundach") +
  xlab("Rozmiar instancji problemu") +
  ylab("Czas dzia�ania algorytmu") +
  theme_bw()
```

```{r best_times_compare}
ggplot(data_times, aes(x = inst_size, y = min)) +
  geom_point() +
  facet_wrap(~ name, ncol = 2) +
  ggtitle("Najkr�tszy czas dzia�ania algorytmu w milisekundach") +
  xlab("Rozmiar instancji problemu") +
  ylab("Czas dzia�ania algorytmu") +
  theme_bw()
```

Przedstawione powy�ej wykresy czasu trwania iteracji algorytm�w pokazuj� wielomianowy wzrost czasu trwania algorytmu wraz ze wzrostem wielko�ci instancji (czego mo�na si� by�o spodziewa�). Dla algorytm�w *SA* i *TS* czas ro�nie znacznie szybciej od pozosta�ych (wielomian wy�szego stopnia).

Wykresy �redniego czasu dzia�ania pokazuj� rosn�c� niestabilno�� mierzonego czasu (kt�ra nie jest jednak zale�na jedynie od wielko�ci instancji). Najmniejsze odchylenia zanotowano dla algorytmu *Steepest LS*, co by�o do przewidzenia. W ka�dym kroku oceni on tak� sam� liczb� s�siad�w (co zajmie tyle samo czasu), wi�c czas trwania algorytmu zale�y wy��cznie od liczby wykonanych krok�w. Poniewa� dla danej instancji wykonuje on zawsze mniej wi�cej tyle samo krok�w (potwierdzaj� to niewielkie odchylenia standardowe na wykresie rozmiar instancji / liczba krok�w), liczba odwiedzonych s�siad�w, a wi�c i czas trwania algorytmu cechuj� si� wysok� stabilno�ci�.

Trudno jednoznacznie okre�li�, kt�ry z algorytm�w przeszukiwania lokalnego dzia�a szybciej. Dla niekt�rych instancji kr�tszy czas osi�gn�� *Steepest*, dla innych *Greedy*. Jest to silnie zwi�zane z kszta�tem przestrzeni rozwi�za�, a nie bezpo�rednio z wielko�ci� instancji.

## Efektywno�� algorytm�w

Przeprowadzono analiz� efektywno�ci algorytm�w. Miar� efektywno�ci opracowano wed�ug za�o�enia, �e najwy�sz� efektywno�� ma algorytm, kt�ry zwraca rozwi�zanie optymalne w czasie zerowym. Miar� efektywno�ci ograniczono do przedzia�u $[0, 1]$ wed�ug poni�szego wzoru:

$efectiveness = \frac{1}{(dist + 1) * (time / 60000 + 1)}$

```{r efectiveness_compare}
data_ef <- data %>%
  mutate(ef = 1/ ((result_dist + 1) * (time/60000 + 1))) %>%
  summarySE(measurevar = "ef", groupvars = c("name", "inst_size"))

ggplot(data_ef %>% filter(name != "Random"), aes(x = inst_size, y = ef)) +
  geom_point() +
  facet_wrap(~ name, ncol = 2) +
  ggtitle("�rednia efektywno�� algorytmu dla danego rozmiaru instancji problemu") +
  xlab("Rozmiar instancji problemu") +
  ylab("Efektywno��") +
  theme_bw()

ggplot(data_ef %>% filter(name == "Random"), aes(x = inst_size, y = ef)) +
  geom_point() +
  ggtitle("�rednia efektywno�� - algorytm losowy") +
  xlab("Rozmiar instancji problemu") +
  ylab("Efektywno��") +
  theme_bw()
```

Pierwsz� obserwacj� jest wyra�nie gorsza efektywno�� algorytmu przeszukiwania losowego. Algorytmy *SA* i *TS*, a szczeg�lnie ten pierwszy, wykazuj� wi�ksz� efektywno�� dla wielu instancji testowych ni� przeszukiwanie lokalne, jednak przez szybciej rosn�cy czas, ich efektywno�� spada dla wi�kszych instancji. Algorytm symulowanego wy�arzania cechuje si� najmniejsz� zmienno�ci� efektywno�ci w zale�no�ci od instancji problemu (najmniejsze odchylenia od funkcji uzyskanej z regresji liniowej).

## Zale�no�� jako�ci rozwi�zania ko�cowego od jako�ci rozwi�zania pocz�tkowego (algorytmy przeszukiwania lokalnego)

Przeprowadzono eksperyment por�wnuj�cy jako�� rozwi�zania pocz�tkowego z jako�ci� rozwi�zania ko�cowego w algorytmach przeszukiwania lokalnego. Wyniki zilustrowano poni�szymi wykresami.

```{r init_result_relation}
data_init_result = read.csv2("gs_init_result.csv", col.names = c("name", "inst_name", "result", "init_result"), dec = ".")

for (i_name in unique(data_init_result$inst_name)) {
  instance_data <- data_init_result %>%
    filter(inst_name == i_name)
  
  print(ggplot(instance_data, aes(x = init_result, y = result)) +
    geom_point() +
    facet_grid(name ~ .) +
    ggtitle(i_name) +
    xlab("Jako�� rozwi�zania pocz�tkowego") +
    ylab("Jako�� rozwi�zania ko�cowego") +
    theme_bw()
  )
}
  
```

Z powy�szych wykres�w wynika, �e nie istnieje wyra�na zale�no�� mi�dzy jako�ci� rozwi�zania pocz�tkowego, a ko�cowego. Pokazuj� one natomiast charakter badanych instancji problemu, w kt�rych okre�lone rozwi�zania wyst�puj� cz��ciej od innych (poziome "linie" na wykresach).

Brak zale�no�ci mi�dzy jako�ci� pocz�tkowego i ko�cowego rozwi�zania wynika ze z�o�onego kszta�tu powierzchni rozwi�za�. Algorytmy przeszukiwania lokalnego znajduj� lokalne optimum, a nie mamy �adnej gwarancji, �e w okolicach dobrego rozwi�zania b�dzie dobre optimum lokalne. Jedyn� gwarancj� dan� nam przez algorytmy przeszukiwania lokalnego jest fakt, �e rozwi�zanie ko�cowe b�dzie zawsze nie gorsze od pocz�tkowego.

## Multi-random local search: Zale�no�� uzyskanego rozwi�zania od liczby restart�w

Dla dw�ch algorytm�w przeszukiwania lokalnego (*Greedy* i *Steepest*) przeprowadzono eksperyment sprawdzaj�cy zale�no�� jako�ci uzyskanego rozwi�zania od ilo�ci restart�w (ponownych przeszukiwa� lokalnych zaczynaj�cych od losowo wybranych punkt�w pocz�tkowych). Wyniki przedstawiono na poni�szych wykresach.

```{r multi_random}
data_multi_random = read.csv2("multi_random.csv", col.names = c("name", "inst_name", "result", "result_type", "iter_count"), dec = ".")

for (i_name in unique(data_multi_random$inst_name)) {
  instance_data <- data_multi_random %>%
    filter(inst_name == i_name)
  
  print(ggplot(instance_data, aes(x = iter_count, y = result, colour = result_type)) +
    geom_line() +
    facet_grid(name ~ .) +
    labs(title = i_name, x = "Liczba iteracji", y = "Jako�� zwr�conego rozwi�zania", color = "Rodzaj wyniku") +
    theme_bw()
  )
}
```

Zamieszczone wykresy pokazuj�, �e algorytmy stosunkowo szybko (ju� po 2 -- 3 iteracjach) osi�gaj� rozwi�zanie bliskie ko�cowemu (gdzie za ko�cowe  uznajemy takie, kt�re nie zmienia si� przez kilkadziesi�t iteracji). Dalsze iteracje pomagaj� natomiast w coraz wolniejszym tempie poprawia� uzyskane rozwi�zanie. Algorytm *Steepest* szybciej osi�ga ko�cowe rozwi�zanie. Sugeruje to, �e efektywniej eksploruje on przestrze�. Wybieranie za ka�dym razem najlepszego s�siada mo�e wi�c prowadzi� do wi�kszej r��norodno�ci znajdowanych optim�w lokalnych po wielokrotnym uruchomieniu algorytmu. Wi�cej znalezionych optim�w lokalnych zwi�ksza natomiast prawdopodobie�stwo znalezienia optimum globalnego.

## Ocena podobie�stwa znajdywanych rozwi�za� lokalnie optymalnych

Okre�lono podobie�stwo mi�dzy rozwi�zaniami znalezionymi przez algorytmy przeszukiwania lokalnego. Podobie�stwo zosta�o zdefiniowane, jako liczba pozycji, na kt�rych rozwi�zania maj� r�wne warto�ci. Przyk�adowo:

```{r results_similarity}
data_results_similarity <- read.csv2("results_similarity.csv", col.names = c("perm1", "perm2", "similarity", "score1", "score2", "inst_name"), dec = ".") %>%
  mutate(score_dif = abs(score1 - score2))

data_table <- data_results_similarity %>%
  select(perm1, perm2, similarity) %>%
  top_n(5)

kable(data_table, col.names = c("Permutacja 1", "Permutacja 2", "Podobie�stwo"))
```

Sporz�dzono wykresy pr�buj�c zbada� zale�no�� mi�dzy podobie�stwem, a r��nic� w jako�ci dla par rozwi�za�. Badanie przeprowadzono na dw�ch niewielkich instancjach.

```{r results_similarity_graphs}
for (i_name in unique(data_results_similarity$inst_name)) {
  instance_data <- data_results_similarity %>%
    filter(inst_name == i_name)
  
  print(ggplot(instance_data, aes(x = similarity, y = score_dif)) +
    geom_point() +
    ggtitle(i_name) +
    xlab("Podobie�stwo rozwi�za�") +
    ylab("R��nica jako�ci rozwi�za�") +
    theme_bw()
  )
}
```

Wykres dla pierwszej z badanych instancji przedstawia relacj� malej�c� (im bardziej podobne rozwi�zania, tym mniejsza r��nica w ich jako�ci), podczas, gdy drugi nie przejawia wyra�nej relacji omawianych wielko�ci. Rozwi�zania znalezione dla drugiej instancji s� r�wnie� mniej podobne do siebie wzajemnie -- dla instancji problemu *had12* pary rozwi�za� maj� podobie�stwo si�gaj�ce nawet 10 (na maksimum 12), natomiast dla *nug14* najwy�sze podobie�stwo wynios�o 6/14.

## Wnioski

W ramach zadania zaimplementowano i przetestowano 4 algorytmy rozwi�zuj�ce problem QAP: *Random Search*, *Greedy Local Search*, *Steepest Local Search* oraz autorski algorytm heurystyczny. Do przeszukiwania przestrzeni rozwi�za� skorzystano z s�siedztwa 2-OPT, kt�re dla ka�dego rozwi�zania zwraca n<sup>2</sup> jego s�siad�w. 

W pierwszej kolejno�ci por�wnano liczb� wykonanych krok�w oraz sprawdzonych s�siad�w przez algorytmy *Greedy LS* i *Steepest LS*. Okaza�o si�, �e jakkolwiek *Steepest* wykonuje znacznie mniej krok�w dla ka�dej badanej instancji, liczba sprawdzonych przez niego s�siad�w w pe�nej iteracji jest zazwyczaj wy�sza od "konkurenta".

Wzgl�dna odleg�o�� znalezionego rozwi�zania od optimum globalnego jest niezale�na od wielko�ci instancji, a dla algorytmu *Random Search* jest ona nawet tym mniejsza, im wi�ksza jest instancja problemu. Jest to jednak w du�ej mierze znacznym wyd�u�eniem czasu dzia�ania RS dla wi�kszych instancji.

Czas wykonywania algorytm�w ro�nie wraz ze wzrostem wielko�ci instancji. Jest to spodziewany wniosek, jednak nale�y zauwa�y�, �e od tej regu�y s� wyj�tki i d�ugo�� permutacji nie jest jedynym kryterium determinuj�cym czas wykonywania algorytmu. Najbardziej stabilny czas wykonywania wykazuje *Steepest Local Search*, co jest zrozumia�e bior�c pod uwag�, �e w ka�dym kroku przeszukuje ca�e dost�pne s�siedztwo (kt�re ma r�wn� liczno�� w ka�dym punkcie przestrzeni rozwi�za�).

Por�wnanie czasu wykonywania algorytm�w *Greedy* i *Steepest* prowadzi do wniosku, �e �aden z nich nie jest jednoznacznie lepszy od drugiego. Zawsze znajdzie si� instancja, dla kt�rej *Greedy* zako�czy si� szybciej oraz taka, dla kt�rej to *Steepest* osi�gnie lepszy czas.

Nie mo�na wskaza� wyra�nej zale�no�ci mi�dzy jako�ci� rozwi�zania pocz�tkowego, a ko�cowego w algorytmach przeszukiwania lokalnego. Jedyn� pewn� zale�no�ci� jest, �e zwr�cone rozwi�zanie b�dzie si� charakteryzowa�o jako�ci� nie gorsz� od pocz�tkowego.

*Multi-random Local Search* (wielokrotne uruchamianie przeszukiwania lokalnego w losowych punktach) stanowi bardzo sprawne ulepszenie algorytm�w LS. Z przeprowadzonych eksperyment�w wynika, �e dobre rozwi�zanie osi�gane jest stosunkowo szybko. Wielokrotne uruchamianie *LS* pozwala na znalezienie wi�kszej liczby optim�w lokalnych, a w konsekwencji zwi�ksza szans� znalezienia rozwi�zania optymalnego globalnie.

Na koniec oceniono podobie�stwo znajdowanych przez *LS* rozwi�za� oraz podj�to pr�b� znalezienia relacji mi�dzy podobie�stwem rozwi�za�, a r��nic� ich jako�ci. Wykorzystano miar� r�wn� liczbie pozycji, na kt�rych permutacje maj� r�wne warto�ci. Zauwa�ono, �e dla niekt�rych instancji mo�e wyst�powa� wyra�na zale�no�� mi�dzy podobie�stwem rozwi�za�, a r��nic� ich jako�ci.

## Napotkane trudno�ci

Przy wykonywaniu zadania nie natrafiono na �adne istotne trudno�ci.

